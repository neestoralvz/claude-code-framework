# Production Docker Compose Configuration
# Optimized for production deployment with enhanced security and monitoring

version: '3.8'

services:
  # Main Dashboard Service - Production Configuration
  ticket-dashboard:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: ticket-dashboard-prod
    restart: always
    
    # Production port mapping with environment-based configuration
    ports:
      - "${DASHBOARD_PORT:-3000}:3000"
      - "${DASHBOARD_ADMIN_PORT:-3001}:3001"
    
    # Production environment variables
    environment:
      - NODE_ENV=production
      - DASHBOARD_PORT=3000
      - DASHBOARD_HOST=0.0.0.0
      - LOG_LEVEL=info
      - CLAUDE_BASE_DIR=/claude-data
      - AUTO_SYNC_ENABLED=true
      - HEALTH_CHECK_ENABLED=true
      - METRICS_ENABLED=true
      - FILE_WATCH_ENABLED=true
      - BACKUP_ON_UPDATE=true
      - VALIDATION_REQUIRED=true
    
    # Production volume configuration
    volumes:
      # Claude data directory (read-write access for full integration)
      - ${CLAUDE_DATA_DIR:-/Users/nalve/.claude}:/claude-data:rw
      
      # Dashboard data persistence with specific mount points
      - prod-dashboard-data:/app/data
      - prod-dashboard-logs:/app/logs
      - prod-dashboard-metrics:/app/metrics
      - prod-dashboard-cache:/app/cache
      - prod-dashboard-config:/app/core
      - prod-dashboard-backups:/app/backups
    
    # Production network
    networks:
      - prod-dashboard-network
    
    # Enhanced health check for production
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 30s
    
    # Production resource limits
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 60s
    
    # Production logging
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=ticket-dashboard,environment=production"

  # Enhanced Backup Service for Production
  backup-service:
    image: alpine:3.18
    container_name: ticket-dashboard-backup-prod
    restart: always
    
    environment:
      - BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-0 2 * * *}
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}
      - BACKUP_COMPRESSION=true
      - BACKUP_ENCRYPTION=${BACKUP_ENCRYPTION:-false}
    
    command: >
      sh -c "
        apk add --no-cache dcron tar gzip gnupg;
        echo '${BACKUP_SCHEDULE:-0 2 * * *} /backup.sh' | crontab -;
        echo '#!/bin/sh
        set -e
        DATE=\$$(date +%Y%m%d_%H%M%S)
        BACKUP_DIR=\"/backups/\$$DATE\"
        mkdir -p \$$BACKUP_DIR
        
        # Create comprehensive backup
        echo \"Starting backup: \$$DATE\"
        tar -czf \$$BACKUP_DIR/dashboard_data.tar.gz -C /data .
        tar -czf \$$BACKUP_DIR/dashboard_logs.tar.gz -C /logs .
        tar -czf \$$BACKUP_DIR/dashboard_metrics.tar.gz -C /metrics .
        tar -czf \$$BACKUP_DIR/dashboard_config.tar.gz -C /config .
        
        # Create backup manifest
        echo \"data_backup=dashboard_data.tar.gz\" > \$$BACKUP_DIR/manifest.txt
        echo \"logs_backup=dashboard_logs.tar.gz\" >> \$$BACKUP_DIR/manifest.txt
        echo \"metrics_backup=dashboard_metrics.tar.gz\" >> \$$BACKUP_DIR/manifest.txt
        echo \"config_backup=dashboard_config.tar.gz\" >> \$$BACKUP_DIR/manifest.txt
        echo \"backup_date=\$$DATE\" >> \$$BACKUP_DIR/manifest.txt
        echo \"backup_size=\$$(du -sh \$$BACKUP_DIR | cut -f1)\" >> \$$BACKUP_DIR/manifest.txt
        
        # Cleanup old backups
        find /backups -type d -name \"20*\" -mtime +${BACKUP_RETENTION_DAYS:-30} -exec rm -rf {} + 2>/dev/null || true
        
        echo \"Backup completed: \$$DATE\"
        echo \"Backup location: \$$BACKUP_DIR\"' > /backup.sh;
        chmod +x /backup.sh;
        
        # Run initial backup
        /backup.sh;
        
        # Start cron daemon
        crond -f;
      "
    
    volumes:
      - prod-dashboard-data:/data:ro
      - prod-dashboard-logs:/logs:ro
      - prod-dashboard-metrics:/metrics:ro
      - prod-dashboard-config:/config:ro
      - prod-dashboard-backups:/backups
    
    networks:
      - prod-dashboard-network
    
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Enhanced Monitoring Service for Production
  monitoring:
    image: alpine:3.18
    container_name: ticket-dashboard-monitor-prod
    restart: always
    
    environment:
      - MONITOR_INTERVAL=${MONITOR_INTERVAL:-30}
      - ALERT_THRESHOLD_CPU=${ALERT_THRESHOLD_CPU:-80}
      - ALERT_THRESHOLD_MEMORY=${ALERT_THRESHOLD_MEMORY:-80}
      - ALERT_THRESHOLD_DISK=${ALERT_THRESHOLD_DISK:-85}
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-}
    
    command: >
      sh -c "
        apk add --no-cache curl jq bc;
        
        # Create monitoring script
        echo '#!/bin/sh
        check_dashboard_health() {
          HEALTH=\$$(curl -f -s --max-time 10 http://ticket-dashboard:3000/health 2>/dev/null || echo \"unhealthy\")
          echo \"\$$(date): Dashboard health check: \$$HEALTH\"
          
          if [ \"\$$HEALTH\" = \"unhealthy\" ]; then
            echo \"ALERT: Dashboard is unhealthy!\"
            # Send alert if webhook configured
            if [ -n \"\$SLACK_WEBHOOK_URL\" ]; then
              curl -X POST -H \"Content-type: application/json\" --data \"{\\\"text\\\":\\\"ðŸš¨ Dashboard Health Alert: Service is unhealthy\\\"}\" \$SLACK_WEBHOOK_URL 2>/dev/null || true
            fi
          fi
        }
        
        check_resource_usage() {
          # Get container stats
          CONTAINER_ID=\$$(docker ps --format \"table {{.ID}}\\t{{.Names}}\" | grep ticket-dashboard-prod | cut -f1)
          if [ -n \"\$CONTAINER_ID\" ]; then
            STATS=\$$(docker stats --no-stream --format \"{{.CPUPerc}},{{.MemPerc}}\" \$CONTAINER_ID)
            CPU_USAGE=\$$(echo \$STATS | cut -d, -f1 | tr -d %)
            MEM_USAGE=\$$(echo \$STATS | cut -d, -f2 | tr -d %)
            
            echo \"Resource usage - CPU: \$CPU_USAGE%, Memory: \$MEM_USAGE%\"
            
            # Check thresholds
            if [ \$(echo \"\$CPU_USAGE > \$ALERT_THRESHOLD_CPU\" | bc -l) -eq 1 ]; then
              echo \"ALERT: High CPU usage: \$CPU_USAGE%\"
            fi
            
            if [ \$(echo \"\$MEM_USAGE > \$ALERT_THRESHOLD_MEMORY\" | bc -l) -eq 1 ]; then
              echo \"ALERT: High memory usage: \$MEM_USAGE%\"
            fi
          fi
        }
        
        # Main monitoring loop
        while true; do
          check_dashboard_health
          check_resource_usage
          sleep \$MONITOR_INTERVAL
        done' > /monitor.sh;
        
        chmod +x /monitor.sh;
        /monitor.sh;
      "
    
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    
    networks:
      - prod-dashboard-network
    
    depends_on:
      - ticket-dashboard
    
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Log Aggregation Service
  log-aggregator:
    image: alpine:3.18
    container_name: ticket-dashboard-logs-prod
    restart: always
    
    command: >
      sh -c "
        apk add --no-cache logrotate;
        
        # Create log rotation configuration
        echo '/logs/*.log {
          daily
          rotate 30
          compress
          delaycompress
          missingok
          notifempty
          create 644 dashboard dashboard
        }' > /etc/logrotate.d/dashboard;
        
        # Run log rotation daily
        while true; do
          logrotate /etc/logrotate.d/dashboard
          sleep 86400  # 24 hours
        done;
      "
    
    volumes:
      - prod-dashboard-logs:/logs
    
    networks:
      - prod-dashboard-network

# Production volumes with enhanced configuration
volumes:
  prod-dashboard-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker-volumes/prod/data
  
  prod-dashboard-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker-volumes/prod/logs
  
  prod-dashboard-metrics:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker-volumes/prod/metrics
  
  prod-dashboard-cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker-volumes/prod/cache
  
  prod-dashboard-config:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker-volumes/prod/config
  
  prod-dashboard-backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/docker-volumes/prod/backups

# Production network with enhanced security
networks:
  prod-dashboard-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "true"
      com.docker.network.driver.mtu: "1500"